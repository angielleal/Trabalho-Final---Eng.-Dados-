# Pipeline de Dados com Spark no DataBricks

## Licença
[MIT License](LICENSE)

Um projeto que implementa um pipeline de dados para leitura, transformação e visualização em um dashboard.

---

### Começando
Estas instruções ajudam a configurar o ambiente local para desenvolvimento e testes.

---

### Desenho de Arquitetura
Adicione aqui o diagrama representando seu pipeline (use ferramentas como [Excalidraw](https://excalidraw.com) ou [Diagrams.net](https://app.diagrams.net)).

---

### Pré-requisitos
- Python 3.9 ou superior
- Apache Spark 3.4.3
- Docker
- Ferramentas de orquestração (e.g., Airflow, Dagster)
- Data Lake (usando Delta Lake ou Apache Iceberg)

---

### Instalação
1. Clone o repositório:
   ```bash
   git clone https://github.com/seu-usuario/data-pipeline-project.git
   cd data-pipeline-project
   ```

2. Configure o ambiente:
   ```bash
   python -m venv venv
   source venv/bin/activate  # No Windows: venv\Scripts\activate
   pip install -r requirements.txt
   ```

3. Configure e inicie o Spark localmente:
   (Detalhe isso no README posteriormente.)

---

### Ferramentas utilizadas
- [Apache Spark](https://spark.apache.org): Transformação de dados
- [Delta Lake](https://delta.io/): Gerenciamento de dados no Data Lake
- [Airflow](https://airflow.apache.org/): Orquestração de tarefas
- [MkDocs](https://www.mkdocs.org): Documentação do projeto

---

### Autores
- Aluno 1: Angiel Leal - (https://github.com/angielleal)
- Aluno 2: Lucas Daufenbach - (https://github.com/seu-usuario)
- Aluno 3: Marcos Jeronimo - (https://github.com/seu-usuario)
- Aluno 2: Mateus Zanin - (https://github.com/seu-usuario)
  
---

### Referências
- [Modelo de Projeto no GitHub](https://github.com/jlsilva01/projeto-ed-satc)

